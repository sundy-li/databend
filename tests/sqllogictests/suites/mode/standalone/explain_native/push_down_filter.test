# push down filter ProjectSet
statement ok
drop table if exists products;

statement ok
create table products(name varchar, details variant);

statement ok
insert into products (name, details) values ('Laptop', '{"brand": "Dell", "colors": ["Black", "Silver"], "price": 1200, "features": {"ram": "16GB", "storage": "512GB"}}'), ('Smartphone', '{"brand": "Apple", "colors": ["White", "Black"], "price": 999, "features": {"ram": "4GB", "storage": "128GB"}}'), ('Headphones', '{"brand": "Sony", "colors": ["Black", "Blue", "Red"], "price": 150, "features": {"battery": "20h", "bluetooth": "5.0"}}');

query T
explain select name, json_path_query(details, '$.features.*') as all_features, json_path_query_first(details, '$.features.*') as first_feature from products where name = 'Laptop' and first_feature = '16GB' and all_features = '512GB';
----
EvalScalar
├── output columns: [products.name (#0), all_features (#3), first_feature (#4)]
├── expressions: [get(1)(json_path_query (#2)), json_path_query_first(products.details (#1), '$.features.*')]
├── estimated rows: 0.12
└── Filter
    ├── output columns: [products.name (#0), products.details (#1), json_path_query (#2)]
    ├── filters: [is_true(TRY_CAST(get(1)(json_path_query (#2)) AS String NULL) = '512GB')]
    ├── estimated rows: 0.12
    └── ProjectSet
        ├── output columns: [products.name (#0), products.details (#1), json_path_query (#2)]
        ├── estimated rows: 0.60
        ├── set returning functions: json_path_query(products.details (#1), '$.features.*')
        └── TableScan
            ├── table: default.default.products
            ├── output columns: [name (#0), details (#1)]
            ├── read rows: 3
            ├── read bytes: 370
            ├── partitions total: 1
            ├── partitions scanned: 1
            ├── pruning stats: [segments: <range pruning: 1 to 1>, blocks: <range pruning: 1 to 1, bloom pruning: 1 to 1>]
            ├── push downs: [filters: [and_filters(products.name (#0) = 'Laptop', TRY_CAST(json_path_query_first(products.details (#1), '$.features.*') AS String NULL) = '16GB')], limit: NONE]
            └── estimated rows: 0.60

query T
select name, json_path_query(details, '$.features.*') as all_features, json_path_query_first(details, '$.features.*') as first_feature from products where name = 'Laptop' and first_feature = '16GB' and all_features = '512GB';
----
Laptop "512GB" "16GB"

query T
explain select name, json_path_query(details, '$.features.*') as all_features, json_path_query_first(details, '$.features.*') as first_feature from products where name = 'Laptop' and first_feature = '16GB';
----
EvalScalar
├── output columns: [products.name (#0), all_features (#3), first_feature (#4)]
├── expressions: [get(1)(json_path_query (#2)), json_path_query_first(products.details (#1), '$.features.*')]
├── estimated rows: 0.60
└── ProjectSet
    ├── output columns: [products.name (#0), products.details (#1), json_path_query (#2)]
    ├── estimated rows: 0.60
    ├── set returning functions: json_path_query(products.details (#1), '$.features.*')
    └── TableScan
        ├── table: default.default.products
        ├── output columns: [name (#0), details (#1)]
        ├── read rows: 3
        ├── read bytes: 370
        ├── partitions total: 1
        ├── partitions scanned: 1
        ├── pruning stats: [segments: <range pruning: 1 to 1>, blocks: <range pruning: 1 to 1, bloom pruning: 1 to 1>]
        ├── push downs: [filters: [and_filters(products.name (#0) = 'Laptop', TRY_CAST(json_path_query_first(products.details (#1), '$.features.*') AS String NULL) = '16GB')], limit: NONE]
        └── estimated rows: 0.60

query T
select name, json_path_query(details, '$.features.*') as all_features, json_path_query_first(details, '$.features.*') as first_feature from products where name = 'Laptop' and first_feature = '16GB';
----
Laptop "16GB" "16GB"
Laptop "512GB" "16GB"

statement ok
drop table products;

# push down filter EvalScalar
statement ok
drop table if exists t1;

statement ok
drop table if exists t2;

statement ok
drop view if exists v1;

statement ok
drop view if exists v2;

statement ok
create table t1(id int);

statement ok
create table t2(sid int, val int);

statement ok
create view v1 as select t2.sid, t2.val from t2;

statement ok
create view v2 AS
select
  t.id as sc,
  coalesce(sum(tb.de), 0) as de
from
  t1 as t
  left outer join (
    select
      t3.sid,
      sum(coalesce(t3.val, 0)) as de
    from
      v1 as t3
    group by
      t3.sid
  ) as tb on(tb.sid = t.id)
group by
  t.id
union
all
select
  t.id as sc,
  0 as de
from
  t1 as t
group by
  t.id

query T
explain select distinct t.sc from v2 t where t.sc = 1;
----
AggregateFinal
├── output columns: [t.id (#0)]
├── group by: [id]
├── aggregate functions: []
├── estimated rows: 0.00
└── AggregatePartial
    ├── output columns: [#_group_by_key]
    ├── group by: [id]
    ├── aggregate functions: []
    ├── estimated rows: 0.00
    └── UnionAll
        ├── output columns: [t.id (#0), de (#8)]
        ├── estimated rows: 0.00
        ├── EvalScalar
        │   ├── output columns: [t.id (#0), de (#8)]
        │   ├── expressions: [if(CAST(is_not_null(sum(tb.de) (#7)) AS Boolean NULL), CAST(assume_not_null(sum(tb.de) (#7)) AS Int64 NULL), true, 0, NULL)]
        │   ├── estimated rows: 0.00
        │   └── AggregateFinal
        │       ├── output columns: [sum(tb.de) (#7), t.id (#0)]
        │       ├── group by: [id]
        │       ├── aggregate functions: [sum(sum(coalesce(t3.val, 0)))]
        │       ├── estimated rows: 0.00
        │       └── AggregatePartial
        │           ├── output columns: [sum(tb.de) (#7), #_group_by_key]
        │           ├── group by: [id]
        │           ├── aggregate functions: [sum(sum(coalesce(t3.val, 0)))]
        │           ├── estimated rows: 0.00
        │           └── HashJoin
        │               ├── output columns: [t.id (#0), sum(coalesce(t3.val, 0)) (#5)]
        │               ├── join type: LEFT OUTER
        │               ├── build keys: [tb.sid (#1)]
        │               ├── probe keys: [t.id (#0)]
        │               ├── filters: []
        │               ├── estimated rows: 0.00
        │               ├── AggregateFinal(Build)
        │               │   ├── output columns: [sum(coalesce(t3.val, 0)) (#5), t2.sid (#1)]
        │               │   ├── group by: [sid]
        │               │   ├── aggregate functions: [sum(sum_arg_0)]
        │               │   ├── estimated rows: 0.00
        │               │   └── AggregatePartial
        │               │       ├── output columns: [sum(coalesce(t3.val, 0)) (#5), #_group_by_key]
        │               │       ├── group by: [sid]
        │               │       ├── aggregate functions: [sum(sum_arg_0)]
        │               │       ├── estimated rows: 0.00
        │               │       └── EvalScalar
        │               │           ├── output columns: [t2.sid (#1), sum_arg_0 (#4)]
        │               │           ├── expressions: [if(CAST(is_not_null(t3.val (#2)) AS Boolean NULL), CAST(assume_not_null(t3.val (#2)) AS Int32 NULL), true, 0, NULL)]
        │               │           ├── estimated rows: 0.00
        │               │           └── TableScan
        │               │               ├── table: default.default.t2
        │               │               ├── output columns: [sid (#1), val (#2)]
        │               │               ├── read rows: 0
        │               │               ├── read bytes: 0
        │               │               ├── partitions total: 0
        │               │               ├── partitions scanned: 0
        │               │               ├── push downs: [filters: [], limit: NONE]
        │               │               └── estimated rows: 0.00
        │               └── TableScan(Probe)
        │                   ├── table: default.default.t1
        │                   ├── output columns: [id (#0)]
        │                   ├── read rows: 0
        │                   ├── read bytes: 0
        │                   ├── partitions total: 0
        │                   ├── partitions scanned: 0
        │                   ├── push downs: [filters: [is_true(t1.id (#0) = 1)], limit: NONE]
        │                   └── estimated rows: 0.00
        └── EvalScalar
            ├── output columns: [t.id (#9), de (#12)]
            ├── expressions: [CAST(de (#11) AS Int64 NULL)]
            ├── estimated rows: 0.00
            └── EvalScalar
                ├── output columns: [t.id (#9), de (#11)]
                ├── expressions: [0]
                ├── estimated rows: 0.00
                └── AggregateFinal
                    ├── output columns: [t.id (#9)]
                    ├── group by: [id]
                    ├── aggregate functions: []
                    ├── estimated rows: 0.00
                    └── AggregatePartial
                        ├── output columns: [#_group_by_key]
                        ├── group by: [id]
                        ├── aggregate functions: []
                        ├── estimated rows: 0.00
                        └── TableScan
                            ├── table: default.default.t1
                            ├── output columns: [id (#9)]
                            ├── read rows: 0
                            ├── read bytes: 0
                            ├── partitions total: 0
                            ├── partitions scanned: 0
                            ├── push downs: [filters: [is_true(t1.id (#9) = 1)], limit: NONE]
                            └── estimated rows: 0.00

statement ok
drop table t1;

statement ok
drop table t2;

statement ok
drop view v1;

statement ok
drop view v2;

# push down alias filter scan
statement ok
drop table if exists t;

statement ok
create table t (x INT);

statement ok
insert into t(x) values (1), (2);

query I
explain select * from t as a(id) where a.id > 1;
----
Filter
├── output columns: [a.x (#0)]
├── filters: [is_true(a.id (#0) > 1)]
├── estimated rows: 0.40
└── TableScan
    ├── table: default.default.t
    ├── output columns: [x (#0)]
    ├── read rows: 2
    ├── read bytes: 24
    ├── partitions total: 1
    ├── partitions scanned: 1
    ├── pruning stats: [segments: <range pruning: 1 to 1>, blocks: <range pruning: 1 to 1, bloom pruning: 0 to 0>]
    ├── push downs: [filters: [is_true(t.x (#0) > 1)], limit: NONE]
    └── estimated rows: 2.00

statement ok
drop table t;
